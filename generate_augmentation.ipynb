{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess.preprocess import load_dataset, compute_label_agg, select_data, sample_class, undersample, no_to_augment\n",
    "from preprocess.datasets import PTBDataset\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "\n",
    "from Augmentation.random_mask import generate_samples_rm\n",
    "from Augmentation.random_noise import generate_samples_noising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available: True\n"
     ]
    }
   ],
   "source": [
    "# Define device for torch\n",
    "use_cuda = True\n",
    "print(\"CUDA is available:\", torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_DATASET = False\n",
    "DATA_PATH = './trainloader.pt' # Stores path to save/load data to augment (only contains the class of interest)\n",
    "CLS = 'HYP' # Class to augment\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data to be augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD_DATASET:\n",
    "    train_loader = torch.load(DATA_PATH)\n",
    "else:\n",
    "    path = './data/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.3/'\n",
    "        \n",
    "    data, raw_labels = load_dataset(path)\n",
    "\n",
    "    labels = compute_label_agg(raw_labels, path)\n",
    "\n",
    "    data, labels, Y = select_data(data, labels)\n",
    "\n",
    "    data, labels, Y = undersample(data, labels, Y)\n",
    "    \n",
    "    max_samples, min_samples = no_to_augment(labels, CLS)\n",
    "    \n",
    "    data, labels, Y = sample_class(data, labels, Y, CLS)\n",
    "\n",
    "    ds = PTBDataset(data, labels, Y)\n",
    "\n",
    "    train_loader = DataLoader(dataset=ds, batch_size=BATCH_SIZE)\n",
    "\n",
    "    torch.save(train_loader, DATA_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate augmented samples by random masking and saving data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_rm = generate_samples_rm(train_loader, min_samples=min_samples, max_samples=max_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, valid_ds, test_ds = torch.utils.data.random_split(ds_rm, [0.8, 0.1, 0.1])\n",
    "\n",
    "train_loader_rm = torch.utils.data.DataLoader(train_ds, batch_size=BATCH_SIZE)\n",
    "valid_loader_rm = torch.utils.data.DataLoader(valid_ds, batch_size=BATCH_SIZE)\n",
    "test_loader_rm = torch.utils.data.DataLoader(test_ds, batch_size=BATCH_SIZE)\n",
    "\n",
    "torch.save(train_loader_rm, './trainloader_augmented_rm.pt')\n",
    "torch.save(valid_loader_rm, './validloader_augmented_rm.pt')\n",
    "torch.save(test_loader_rm, './testloader_augmented_rm.pt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating augmented samples by noising and saving data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_rn = generate_samples_noising(train_loader, batch_size=BATCH_SIZE, min_samples=min_samples, max_samples=max_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_ds, valid_ds, test_ds = torch.utils.data.random_split(ds_rn, [0.8, 0.1, 0.1])\n",
    "\n",
    "train_loader_rn = torch.utils.data.DataLoader(train_ds, batch_size=BATCH_SIZE)\n",
    "valid_loader_rn = torch.utils.data.DataLoader(valid_ds, batch_size=BATCH_SIZE)\n",
    "test_loader_rn = torch.utils.data.DataLoader(test_ds, batch_size=BATCH_SIZE)\n",
    "\n",
    "torch.save(train_loader_rn, './trainloader_augmented_rn.pt')\n",
    "torch.save(valid_loader_rn, './validloader_augmented_rn.pt')\n",
    "torch.save(test_loader_rn, './testloader_augmented_rn.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
